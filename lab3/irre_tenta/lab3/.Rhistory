y = c(33,24,48,32,55,74,23,76, 17)
mu = 3.5
n = 9
# 2.a)
tau_sq = sum((log(y)-mu)^2)/n
X = rchisq(1E5,n)
X_draws = c()
#theta_draws = c()
# can be optimized by using rchisq(1E5,n)
for (tmp in 1:1E5)
{s
X = rchisq(1,n)       # our posterior is scaled InvâÏ2(n,Ï2) hence using n instead of n-1 as in slides
X_draws = c(X_draws,X)
#theta_draw = rnorm(1,mean(X_draws),sigma_sq/n)   # not required as sampling theta is used to get the marginal posterior
#theta_draws = c(theta_draws,theta_draw)
}
sigma_sq = (n)*tau_sq / X_draws   # our posterior is scaled InvâÏ2(n,Ï2) hence using n instead of n-1 as in slides
inversechisq <- function(x, v, s){
density = (((v/2)^(v/2))/gamma(v/2)) * (s^v) * (x^(-(v/2+1))) * (exp((-v*s^2)/(2*x)))
return (density)
}
plot(density(sigma_sq))        # Plotting posterior draws from sampling
lines(seq(0.1,6,by=0.1), inversechisq(seq(0.1,6,by=0.1), n, sqrt(tau_sq)), type = "l", col =  "red")  # Plotting posterior distribution using density function
# 2.b)
distribution_gini = 2 * pnorm(sqrt(sigma_sq/2)) - 1
plot(density(distribution_gini))
clear
library(manipulate)
sucess <- 13
n_trails <- 50
failures <- 37
alpha <- 5
beta <- 5
# Task 1. a)
# Function to calculcate and plot mean of posterior Distribution Random Draws
PosteriorDraws_MeanPlot <- function(alpha, beta, n, sucess_proportions){
mean_posterior <-  list()
for(i in 1:n){
posterior_draws = rbeta(i, alpha+sucess, beta+failures)
mean_posterior[i] <- mean(posterior_draws)
}
print(mean_posterior[n])
plot(c(1:n), mean_posterior, type = 'l', lwd = 1, col = "blue", xlab = "number of Random Draws",
ylab = 'mean of Draws', main = 'Mean plot Posteriors')
}
# Function to calculcate and plot SD of posterior Distribution Random Draws
PosteriorDraws_SDPlot <- function(alpha, beta, n, sucess_proportions){
sd_posterior <- list()
for(i in 1:n){
posterior_draws = rbeta(i, alpha+sucess, beta+failures)
sd_posterior[i] <- sd(posterior_draws)
}
print(sd_posterior[n])
plot(c(1:n), sd_posterior, type = 'l', lwd = 1, col = "red", xlab = "number of Random Draws",  ylab = 'SD of Draws', main = 'SD plot Posteriors')
}
manipulate(
PosteriorDraws_MeanPlot(alpha, beta, n, sucess/n_trails),
n = slider(1, 100000, step=100, initial = 10000, label = "Number of trails(Random Draws)")
)
manipulate(
PosteriorDraws_SDPlot(alpha, beta, n, sucess/n_trails),
n = slider(1, 100000, step=100, initial = 10000, label = "Number of trails(Random Draws)")
)
# True mean of beta distribution -> alpha/(alpha+beta), so true mean of posterior
true_mean = (alpha+sucess)/((alpha+sucess)+(beta+failures))
print(true_mean)
# True variance of beta distribution -> (alpha*beta)/((alpha+beta+1) * (alpha + beta)^2)
true_sd = sqrt(((alpha+sucess)*(beta+failures))/((alpha+sucess+beta+failures+1) * (alpha + sucess + beta + failures)^2))
print(true_sd)
# Task 1. b)
posterior_draws <-  rbeta(10000, alpha+sucess, beta+failures)              # taking 10000 random draws from the posterior beta distribution
count_density_less <- length(posterior_draws[posterior_draws<0.3])         # counting number of draws with value less than 0.3
posterior_probablity_less <- count_pobablity_less/10000                    # calculating probability of draws with value < 0.3
posterior_probablity_less_exact <- pbeta(0.3, alpha+sucess, beta+failures) # using pbeta to find the same probability using cumulative frequency of beta distribution
posterior_probablity_less_exact
posterior_probablity_less
posterior_draws <-  rbeta(10000, alpha+sucess, beta+failures)              # taking 10000 random draws from the posterior beta distribution
posterior_logodds <- log(posterior_draws/(1-posterior_draws))              # converting to log odds using simulated draws from beta posterior
hist(posterior_logodds)                                                    # plotting posterior distribution of log-odds
plot(density(posterior_logodds))                                           # plotting posterior distribution of log-odds
library(manipulate)
sucess <- 13
n_trails <- 50
failures <- 37
alpha <- 5
beta <- 5
# Task 1. a)
# Function to calculcate and plot mean of posterior Distribution Random Draws
PosteriorDraws_MeanPlot <- function(alpha, beta, n, sucess_proportions){
mean_posterior <-  list()
for(i in 1:n){
posterior_draws = rbeta(i, alpha+sucess, beta+failures)
mean_posterior[i] <- mean(posterior_draws)
}
print(mean_posterior[n])
plot(c(1:n), mean_posterior, type = 'l', lwd = 1, col = "blue", xlab = "number of Random Draws",
ylab = 'mean of Draws', main = 'Mean plot Posteriors')
}
# Function to calculcate and plot SD of posterior Distribution Random Draws
PosteriorDraws_SDPlot <- function(alpha, beta, n, sucess_proportions){
sd_posterior <- list()
for(i in 1:n){
posterior_draws = rbeta(i, alpha+sucess, beta+failures)
sd_posterior[i] <- sd(posterior_draws)
}
print(sd_posterior[n])
plot(c(1:n), sd_posterior, type = 'l', lwd = 1, col = "red", xlab = "number of Random Draws",  ylab = 'SD of Draws', main = 'SD plot Posteriors')
}
manipulate(
PosteriorDraws_MeanPlot(alpha, beta, n, sucess/n_trails),
n = slider(1, 100000, step=100, initial = 10000, label = "Number of trails(Random Draws)")
)
manipulate(
PosteriorDraws_SDPlot(alpha, beta, n, sucess/n_trails),
n = slider(1, 100000, step=100, initial = 10000, label = "Number of trails(Random Draws)")
)
# True mean of beta distribution -> alpha/(alpha+beta), so true mean of posterior
true_mean = (alpha+sucess)/((alpha+sucess)+(beta+failures))
print(true_mean)
# True variance of beta distribution -> (alpha*beta)/((alpha+beta+1) * (alpha + beta)^2)
true_sd = sqrt(((alpha+sucess)*(beta+failures))/((alpha+sucess+beta+failures+1) * (alpha + sucess + beta + failures)^2))
print(true_sd)
sd(c(1,2,2,3))
sd
library(mvtnorm)
data <- read.table("eBayNumberOfBidderData.dat", sep = "" , header = T , na.strings ="", stringsAsFactors= F)
data = as.data.frame(data)
col_names = colnames(data)
# lab 3.2.1
model <- glm(nBids ~ . , data[,-2], family = poisson(link = "log"))
model
summary(model)
setwd("C:/Users/IsakG/projects/baysian-learning/lab3")
library(mvtnorm)
data <- read.table("eBayNumberOfBidderData.dat", sep = "" , header = T , na.strings ="", stringsAsFactors= F)
data = as.data.frame(data)
col_names = colnames(data)
# lab 3.2.1
model <- glm(nBids ~ . , data[,-2], family = poisson(link = "log"))
model
summary(model)
# lab 3.2.2
Y = data$nBids
X = as.matrix(data[,-1])
n = dim(data)[1]
mu = rep(0,9)
Sigma = 100*solve(t(X)%*%X)
beta_prior = rmvnorm(1,mean=mu,sigma=Sigma)
dim(beta_prior)
LogPostPoisson <- function(betas,Y,X,mu,Sigma){
linPred <- betas%*%t(X);
# finding the log likelihood
logLik <- sum(Y*linPred - exp(linPred) - log(factorial(Y)));
#print(logLik)
# finding the log logPrior using the parameters given
logPrior <- dmvnorm(betas, mu, Sigma, log=TRUE);
#print(logPrior)
# returning the log posterior as the sum of loglikihood and logPrior
return(logLik + logPrior)
}
OptimRes <- optim(beta_prior,LogPostPoisson,gr=NULL,Y,X,mu,Sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
# Getting the hessian matrix from the results returned from the optim function
beta_mode_hessian = OptimRes$hessian
# Getting the mode Î² values as the parameters returned from the optim function
beta_mode = OptimRes$par
colnames(beta_mode) = col_names[-1]
# Getting the J(beta_mode) as the negative of the hessian returned
J = -beta_mode_hessian
# Calculating inverse of J
J_inverse = solve(-beta_mode_hessian)
posterior_beta_draw = rmvnorm(1,beta_mode, J_inverse)
# lab 3.2.3
num_random_walk = 1E5
MetropolisRandomWalk <- function(beta_initial, c, J_inverse, log_density_function, mu, Sigma, Y, X){
metropolis_betas = matrix(data = NA, nrow = num_random_walk, ncol = dim(X)[2])
prev_beta = beta_initial
for(i in 1:num_random_walk){
sample = rmvnorm(1, mean = prev_beta, sigma = c * J_inverse)
log_density_sample = log_density_function(sample, Y, X, mu, Sigma)
log_density_prev_sample = log_density_function(prev_beta, Y, X, mu, Sigma)
alpha = min(1, exp((log_density_sample - log_density_prev_sample)))
rand = runif(n=1, min = 0, max = 1)
if(rand<alpha){
metropolis_betas[i,] = sample
prev_beta = sample
}
else{
metropolis_betas[i,] = prev_beta
}
}
return(metropolis_betas)
}
metropolis_posterior_betas = MetropolisRandomWalk(posterior_beta_draw, .6, J_inverse, LogPostPoisson, mu, Sigma, Y, X)
colnames(metropolis_posterior_betas) = col_names[-1]
par(mfrow=c(3,3))
for(i in 1:dim(X)[2]){
plot(metropolis_posterior_betas[,i], type = "l", ylim = c(0,2*model$coefficients[i]))
abline(h=model$coefficients[i], col="red")
}
par(mfrow=c(1,1))
sample = matrix(c(1, 1, 0, 1, 0, 1,0,1.2,0.8))
prediction = exp(metropolis_posterior_betas %*% sample)
print(exp(model$coefficients%*%sample))
hist(prediction, main = "Predictive distribution", sub =paste("glm predicts: ",exp(model$coefficients%*%sample)))
prob_no_bids = mean(rpois(num_random_walk,prediction)==0)
par(mfrow=c(3,3))
for(i in 1:dim(X)[2]){
plot(metropolis_posterior_betas[,i], type = "l", ylim = c(0,2*model$coefficients[i]),main=col_names[1+i])
abline(h=model$coefficients[i], col="red")
}
par(mfrow=c(1,1))
sample = matrix(c(1, 1, 0, 1, 0, 1,0,1.2,0.8))
prediction = exp(metropolis_posterior_betas %*% sample)
print(exp(model$coefficients%*%sample))
hist(prediction, main = "Predictive distribution", sub =paste("glm predicts: ",exp(model$coefficients%*%sample)))
prob_no_bids = mean(rpois(num_random_walk,prediction)==0)
par(mfrow=c(3,3))
for(i in 1:dim(X)[2]){
plot(metropolis_posterior_betas[,i], type = "l", ylim = c(0,2*model$coefficients[i]),ylab = col_names[1+i])
abline(h=model$coefficients[i], col="red")
}
prob_no_bids = mean(rpois(num_random_walk,prediction)==0)
prob_no_bids
rpos(10,.5)
rpois(10,.5)
mean(rpois(10,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mean(rpois(2,.5))
mu = 13
sigma_sq = 3
t_max = 300
fi = 1
# ------------------ 3.3.1
#num
par(mfrow=c(3,2))
for (fi in seq(-.8,.8,.8)){
path = matrix(nrow = t_max)
path[1] = mu
for (t in 2:t_max){
path[t] = mu + fi*(path[t-1]-mu) + rnorm(1,0,sigma_sq)
}
plot(path,main=fi,type="line",col="blue")
acf(path,main=paste("ACF ",fi))
for (fi in seq(-.8,.8,.8)){
path = matrix(nrow = t_max)
path[1] = mu
for (t in 2:t_max){
path[t] = mu + fi*(path[t-1]-mu) + rnorm(1,0,sigma_sq)
}
plot(path,main=fi,type="line",col="blue")
acf(path,main=paste("ACF ",fi))
}
mu = 13
sigma_sq = 3
t_max = 300
fi = 1
# ------------------ 3.3.1
#num
par(mfrow=c(3,2))
for (fi in seq(-.8,.8,.8)){
path = matrix(nrow = t_max)
path[1] = mu
for (t in 2:t_max){
path[t] = mu + fi*(path[t-1]-mu) + rnorm(1,0,sigma_sq)
}
plot(path,main=fi,type="line",col="blue")
acf(path,main=paste("ACF ",fi))
}
mu = 13
sigma_sq = 3
t_max = 300
fi = 1
# ------------------ 3.3.1
#num
par(mfrow=c(3,2))
for (fi in seq(-.8,.8,.8)){
path = matrix(nrow = t_max)
path[1] = mu
for (t in 2:t_max){
path[t] = mu + fi*(path[t-1]-mu) + rnorm(1,0,sigma_sq)
}
plot(path,main=fi,type="line",col="blue")
acf(path,main=paste("ACF ",fi))
}
mu = 13
sigma_sq = 3
t_max = 300
fi = 1
# ------------------ 3.3.1
#num
par(mfrow=c(3,2))
for (fi in seq(-.8,.8,.8)){
path = matrix(nrow = t_max)
path[1] = mu
for (t in 2:t_max){
path[t] = mu + fi*(path[t-1]-mu) + rnorm(1,0,sigma_sq)
}
plot(path,main=fi,type="line",col="blue")
acf(path,main=paste("ACF ",fi))
}
plot(runif(100))
