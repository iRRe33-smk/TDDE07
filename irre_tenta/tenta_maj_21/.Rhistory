library(geoR)
library(mvtnorm)
PostDraws <- BayesLinReg(y, X, mu_0, Omega_0, v_0, sigma2_0, nIter)
Betas <- PostDraws$betaSample
# Reading the data from file
load(file = 'UniversityEntrance.RData')
setwd("C:/Users/IsakG/projects/baysian-learning/irre_tenta/tenta_maj_21")
# Reading the data from file
load(file = 'UniversityEntrance.RData')
mu_0 <- as.vector(rep(0,7))
Omega_0 <- (1/25)*diag(7)
v_0 <- 1
sigma2_0 <- 4
nIter <- 100
library(geoR)
library(mvtnorm)
PostDraws <- BayesLinReg(y, X, mu_0, Omega_0, v_0, sigma2_0, nIter)
Betas <- PostDraws$betaSample
#--------------------------------3.a--------------------
library(geoR)
library(mvtnorm)
head(X)
#priors
#sigma_sq_0 = rinvchisq(n = 1,df = 1,scale = 2^2)
ncovs = dim(X)[2]
mu_0 = rep(0,ncovs)
omega_0 = 1/25*diag(ncovs)
nu_0 = 1
sigma_sq_0 = 2^2
#BayesLinReg(y,X,mu_0,omega_0,nu_0,sigma_sq_0,10000)
draws = BayesLinReg(y = y,X = X,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
'mu_0 <- as.vector(rep(0,7))
Omega_0 <- (1/25)*diag(7)
v_0 <- 1
sigma2_0 <- 4
nIter <- 100
library(geoR)
library(mvtnorm)
PostDraws <- BayesLinReg(y, X, mu_0, Omega_0, v_0, sigma2_0, nIter)
-
Betas <- PostDraws$betaSample
'
draws
summary(draws)
draws$betaSample
head(draws$betaSample)
intervals
draws = BayesLinReg(y = y,X = X,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
intervals = matrix(ncovs,2)
for (i in 1:ncovs){
intervals[i,] = quantile(draws$betaSample[,i])
}
intervals
intervals = matrix(ncovs,2)
for (i in 1:ncovs){
intervals[i,] = quantile(draws$betaSample[,i],probs=c(0,025,0,975))
}
intervals
intervals[i,] = quantile(draws$betaSample[,i],probs=c(0.025,0.975))
for (i in 1:ncovs){
intervals[i,] = quantile(draws$betaSample[,i],probs=c(0.025,0.975))
}
intervals
intervals = matrix(ncovs,2)
for (i in 1:ncovs){
intervals[i,] = quantile(draws$betaSample[,i],probs=c(0.025,0.975))
}
intervals
quantile(draws$betaSample[,1],probs=c(0.025,0.975))
intervals = matrix(nrows=ncovs,ncols=2)
intervals = matrix(nrow=ncovs,ncol=2)
for (i in 1:ncovs){
intervals[i,] = quantile(draws$betaSample[,i],probs=c(0.025,0.975))
}
intervals
intervals
intervals
eoR)
library(mvtnorm)
head(X)
#priors
#sigma_sq_0 = rinvchisq(n = 1,df = 1,scale = 2^2)
ncovs = dim(X)[2]
mu_0 = rep(0,ncovs)
omega_0 = 1/25*diag(ncovs)
nu_0 = 1
sigma_sq_0 = 2^2
#BayesLinReg(y,X,mu_0,omega_0,nu_0,sigma_sq_0,10000)
draws = BayesLinReg(y = y,X = X,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
intervals = matrix(nrow=ncovs,ncol=3)
for (i in 1:ncovs){
draw_i = draws$betaSample[,i]
intervals[i,c(1,3)] = quantile(draw_i,probs=c(0.025,0.975))
intervals[i,2] = mean(draw_i)
}
intervals
intervals = matrix(nrow=ncovs,ncol=3)
colnames(intervals) = c("2.5%","mean","97.5%")
for (i in 1:ncovs){
draw_i = draws$betaSample[,i]
intervals[i,c(1,3)] = quantile(draw_i,probs=c(0.025,0.975))
intervals[i,2] = mean(draw_i)
}
intervals
intervals = matrix(nrow=ncovs,ncol=3)
colnames(intervals) = c("2.5%","mean","97.5%")
rownames(intervals) = colnames(X)
#-------------------1.a-------------------
#prior
a = 16
b = 24
n=100
choice_a = 38
choice_b = 27
choice_c = 35
#posterior
val = .4
prob_less_than = pbeta(val,shape1 = (a+choice_a), shape2 = (a+b+n))
print(prob_less_than)
N = 1E3
random_draws = rbeta(N,shape1 = (a+choice_a), shape2 = (a+b+n))
hist(1-random_draws,probability=TRUE, main = "probability distribution of 1-Theta_a", sub = paste("prob theta_a < ",val, " = ",prob_less_than,sep=""))
#-----------------------------1.b------------------
rat = (1-random_draws)/random_draws
hist(rat)
q=quantile(x=rat,probs=c(0.025,0.975))
abline(v=q, col="red")
1/(1+q)
#---------------------1.c----------------
#marginal likelihood
#posterior over prior. When conjugate prior
marg= beta(a+choice_a,a+b+n) / beta(a,b)
#-----------------------1.d----------------
alpha = 60*c(1,1,1)/3
y= c(38,27,35)
n=1E5
rDirichlet = function(n,alpha,y){
z = matrix(nrow=n,ncol=length(alpha))
for (j in 1:n){
x = matrix(nrow=1,ncol=length(alpha))
for (i in 1:length(alpha)){
x[1,i] = rgamma(n=1,shape =a+y[i])
}
z[j,] = x / sum(x)
}
return(z)
}
z = rDirichlet(n,alpha,y)
posterior_prob = mean(z[,1] > z[,3])
print(posterior_prob)
#--------------------------------3.a--------------------
library(geoR)
library(mvtnorm)
head(X)
#priors
#sigma_sq_0 = rinvchisq(n = 1,df = 1,scale = 2^2)
ncovs = dim(X)[2]
mu_0 = rep(0,ncovs)
omega_0 = 1/25*diag(ncovs)
nu_0 = 1
sigma_sq_0 = 2^2
#BayesLinReg(y,X,mu_0,omega_0,nu_0,sigma_sq_0,10000)
draws = BayesLinReg(y = y,X = X,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
intervals = matrix(nrow=ncovs,ncol=3)
colnames(intervals) = c("2.5%","mean","97.5%")
rownames(intervals) = colnames(X)
for (i in 1:ncovs){
draw_i = draws$betaSample[,i]
intervals[i,c(1,3)] = quantile(draw_i,probs=c(0.025,0.975))
intervals[i,2] = mean(draw_i)
}
intervals
posterior_median = median(draws$sigma2Sample)
posterior_median
head(X)
B_students = x[,"x3"]==1
B_students = X[,"x3"]==1
B_students = X[,"x3"]==1
y_B = y[B_students]
X_b = X[B_students,]
draws_B = BayesLinReg(y = y_B,X = X_B,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
B_students = X[,"x3"]==1
y_B = y[B_students]
X_b = X[B_students,]
draws_B = BayesLinReg(y = y_B,X = X_B,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
B_students = X[,"x3"]==1
y_B = y[B_students]
X_B = X[B_students,]
draws_B = BayesLinReg(y = y_B,X = X_B,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
intervals
#----------------------3.c----------------
intervals
#----------------------3.c----------------
intervals[c("x1","x1*x3","x1*x4")]
#----------------------3.c----------------
intervals[c("x1","x1*x3","x1*x4"),]
beta1 = draws$betaSample[2,]
beta5 = draws$betaSample[6,]
beta6 = draws$betaSample[7,]
beta1 = draws$betaSample[2,]
beta5 = draws$betaSample[6,]
beta6 = draws$betaSample[7,]
b1_B = beta1 + beta5
b1_c = beta1 + beta6
diff = b1_B - b1_C
beta1 = draws$betaSample[2,]
beta5 = draws$betaSample[6,]
beta6 = draws$betaSample[7,]
b1_B = beta1 + beta5
b1_C = beta1 + beta6
diff = b1_B - b1_C
plot(density(diff))
knitr::opts_chunk$set(echo = TRUE,results="markup")
rm(list=ls())
source("ExamData.R")
set.seed(1)
alpha <- 16
beta <- 24
n <- 100
s <- 38
f <- n - s
post_alpha <- alpha + s
post_beta <- beta + f
theta_A <- rbeta(1e4, post_alpha, post_beta)
pbeta(0.4, post_alpha, post_beta, lower.tail = FALSE)
plot(density(1-theta_A),type="l",main="Posterior distribution",xlab="1 - theta",ylab="")
Ratio <- (1-theta_A)/theta_A
quantile(Ratio,probs=c(0.025,0.975))
beta(post_alpha,post_beta)/beta(alpha,beta) # Ratio of beta functions
########################################################################################
# Generate samples from the joint posterior distribution of theta=(theta_1,...,theta_K)
# for the multinomial model with K categories and a Dirichlet prior for theta.
########################################################################################
Dirichlet <- function(NDraws,y,alpha){
K <- length(alpha)
xDraws <- matrix(0,NDraws,K)
thetaDraws <- matrix(0,NDraws,K) # Matrix where the posterior draws of theta are stored
for (j in 1:K){
xDraws[,j] <- rgamma(NDraws,shape=alpha[j]+y[j],rate=1)
}
for (ii in 1:NDraws){
thetaDraws[ii,] <- xDraws[ii,]/sum(xDraws[ii,])
}
return(thetaDraws)
}
y_count <- c(38,27,35) # Data of counts for each category
alpha_const <- 20
alpha <- alpha_const*c(1,1,1) # Dirichlet prior hyperparameters
NDraws <- 1e5 # Number of posterior draws
###########   Posterior sampling from Dirichlet  #################
thetaDraws <- Dirichlet(NDraws,y_count,alpha)
mean(thetaDraws[,1] > thetaDraws[,3])
LogPost <- function(theta,n,Sumx2){
logLik <- n*log(theta) -  Sumx2*theta;
logPrior <- -0.5*theta;
return(logLik + logPrior)
}
theta_grid <- seq(0.01,10,0.01)
PostDens_propto <- exp(LogPost(theta_grid,13,2.8))
PostDens <- PostDens_propto/(0.01*sum(PostDens_propto))
plot(theta_grid,PostDens,main="Posterior distribution",xlab="theta", ylab="")
n <- 13
Sumx2 <- 2.8
OptRes <- optim(3,LogPost,gr=NULL,n,Sumx2,method=c("L-BFGS-B"),lower=0.1,
control=list(fnscale=-1),hessian=TRUE)
plot(theta_grid,PostDens,col="blue",main="Posterior distribution",xlab="theta", ylab="")
lines(theta_grid,dnorm(theta_grid,mean = OptRes$par,sd = sqrt(-1/OptRes$hessian)),col="red")
legend("topleft", legend=c("Approximation", "Exact"), col=c("red", "blue"), lty=1:2, cex=0.8)
mu_0 <- as.vector(rep(0,7))
Omega_0 <- (1/25)*diag(7)
v_0 <- 1
sigma2_0 <- 4
nIter <- 10000
library(geoR)
library(mvtnorm)
PostDraws <- BayesLinReg(y, X, mu_0, Omega_0, v_0, sigma2_0, nIter)
Betas <- PostDraws$betaSample
Means <- colMeans(Betas)
CredInt <- matrix(0,7,2)
for (j in 1:7){
CredInt[j,] <- quantile(Betas[,j],probs=c(0.025,0.975))
}
PostRes <- matrix(0,7,3)
PostRes[,1] <- t(Means)
PostRes[,2:3] <- CredInt
PostRes
Sigma2 <- PostDraws$sigma2Sample
median(sqrt(Sigma2))
Effect_B <- Betas[,2] + Betas[,6]
Effect_C <- Betas[,2] + Betas[,7]
Diff <- Effect_B - Effect_C
plot(density(Diff),main="Posterior distribution",xlab="Beta_5 - Beta_6", ylab="")
quantile(Diff,probs=c(0.025,0.975))
plot(density(diff))
#-------------------1.a-------------------
#prior
a = 16
b = 24
n=100
choice_a = 38
choice_b = 27
choice_c = 35
#posterior
val = .4
prob_less_than = pbeta(val,shape1 = (a+choice_a), shape2 = (a+b+n))
print(prob_less_than)
N = 1E3
random_draws = rbeta(N,shape1 = (a+choice_a), shape2 = (a+b+n))
hist(1-random_draws,probability=TRUE, main = "probability distribution of 1-Theta_a", sub = paste("prob theta_a < ",val, " = ",prob_less_than,sep=""))
#-----------------------------1.b------------------
rat = (1-random_draws)/random_draws
hist(rat)
q=quantile(x=rat,probs=c(0.025,0.975))
abline(v=q, col="red")
1/(1+q)
#---------------------1.c----------------
#marginal likelihood
#posterior over prior. When conjugate prior
marg= beta(a+choice_a,a+b+n) / beta(a,b)
#-----------------------1.d----------------
alpha = 60*c(1,1,1)/3
y= c(38,27,35)
n=1E5
rDirichlet = function(n,alpha,y){
z = matrix(nrow=n,ncol=length(alpha))
for (j in 1:n){
x = matrix(nrow=1,ncol=length(alpha))
for (i in 1:length(alpha)){
x[1,i] = rgamma(n=1,shape =a+y[i])
}
z[j,] = x / sum(x)
}
return(z)
}
z = rDirichlet(n,alpha,y)
posterior_prob = mean(z[,1] > z[,3])
print(posterior_prob)
#--------------------------------3.a--------------------
library(geoR)
library(mvtnorm)
head(X)
#priors
#sigma_sq_0 = rinvchisq(n = 1,df = 1,scale = 2^2)
ncovs = dim(X)[2]
mu_0 = rep(0,ncovs)
omega_0 = 1/25*diag(ncovs)
nu_0 = 1
sigma_sq_0 = 2^2
#BayesLinReg(y,X,mu_0,omega_0,nu_0,sigma_sq_0,10000)
draws = BayesLinReg(y = y,X = X,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
intervals = matrix(nrow=ncovs,ncol=3)
colnames(intervals) = c("2.5%","mean","97.5%")
rownames(intervals) = colnames(X)
for (i in 1:ncovs){
draw_i = draws$betaSample[,i]
intervals[i,c(1,3)] = quantile(draw_i,probs=c(0.025,0.975))
intervals[i,2] = mean(draw_i)
}
intervals
#interval for b1 /x1 is positive indicating that the variable x1 is significant to our data.
#----------------------3.b---------------
posterior_median = median(draws$sigma2Sample)
posterior_median
#----------------------3.c----------------
intervals[c("x1","x1*x3","x1*x4"),]
beta1 = draws$betaSample[2,]
beta5 = draws$betaSample[6,]
beta6 = draws$betaSample[7,]
b1_B = beta1 + beta5
b1_C = beta1 + beta6
diff = b1_B - b1_C
plot(density(diff))
clear
#install.packages("geoR")
library(geoR)
# Bayesian Learning Exam 2021-06-03
# Run this file once during the exam to get all the required data
# and functions for the exam in working memory
# Author: Bertil Wegmann
###############################
########## Problem 1 ##########
###############################
###############################
########## Problem 2 ##########
###############################
###############################
########## Problem 3 ##########
###############################
# Reading the data from file
load(file = 'UniversityEntrance.RData')
#install.packages("geoR")
library(geoR)
BayesLinReg <- function(y, X, mu_0, Omega_0, v_0, sigma2_0, nIter){
# Direct sampling from a Gaussian linear regression with conjugate prior:
#
# beta | sigma2 ~ N(mu_0, sigma2*inv(Omega_0))
# sigma2 ~ Inv-Chi2(v_0,sigma2_0)
#
# INPUTS:
#   y - n-by-1 vector with response data observations
#   X - n-by-nCovs matrix with covariates, first column should be ones if you want an intercept.
#   mu_0 - prior mean for beta
#   Omega_0  - prior precision matrix for beta
#   v_0      - degrees of freedom in the prior for sigma2
#   sigma2_0 - location ("best guess") in the prior for sigma2
#   nIter - Number of samples from the posterior (iterations)
#
# OUTPUTS:
#   results$betaSample     - Posterior sample of beta.     nIter-by-nCovs matrix
#   results$sigma2Sample   - Posterior sample of sigma2.   nIter-by-1 vector
# Compute posterior hyperparameters
n = length(y) # Number of observations
nCovs = dim(X)[2] # Number of covariates
XX = t(X)%*%X
betaHat <- solve(XX,t(X)%*%y)
Omega_n = XX + Omega_0
mu_n = solve(Omega_n,XX%*%betaHat+Omega_0%*%mu_0)
v_n = v_0 + n
sigma2_n = as.numeric((v_0*sigma2_0 + ( t(y)%*%y + t(mu_0)%*%Omega_0%*%mu_0 - t(mu_n)%*%Omega_n%*%mu_n))/v_n)
invOmega_n = solve(Omega_n)
# The actual sampling
sigma2Sample = rep(NA, nIter)
betaSample = matrix(NA, nIter, nCovs)
for (i in 1:nIter){
# Simulate from p(sigma2 | y, X)
sigma2 = rinvchisq(n=1, df=v_n, scale = sigma2_n)
sigma2Sample[i] = sigma2
# Simulate from p(beta | sigma2, y, X)
beta_ = rmvnorm(n=1, mean = mu_n, sigma = sigma2*invOmega_n)
betaSample[i,] = beta_
}
return(results = list(sigma2Sample = sigma2Sample, betaSample=betaSample))
}
#-------------------1.a-------------------
#prior
a = 16
b = 24
n=100
choice_a = 38
choice_b = 27
choice_c = 35
#posterior
val = .4
prob_less_than = pbeta(val,shape1 = (a+choice_a), shape2 = (a+b+n))
print(prob_less_than)
N = 1E3
random_draws = rbeta(N,shape1 = (a+choice_a), shape2 = (a+b+n))
hist(1-random_draws,probability=TRUE, main = "probability distribution of 1-Theta_a", sub = paste("prob theta_a < ",val, " = ",prob_less_than,sep=""))
#-----------------------------1.b------------------
rat = (1-random_draws)/random_draws
hist(rat)
q=quantile(x=rat,probs=c(0.025,0.975))
abline(v=q, col="red")
1/(1+q)
#---------------------1.c----------------
#marginal likelihood
#posterior over prior. When conjugate prior
marg= beta(a+choice_a,a+b+n) / beta(a,b)
#-----------------------1.d----------------
alpha = 60*c(1,1,1)/3
y= c(38,27,35)
n=1E5
rDirichlet = function(n,alpha,y){
z = matrix(nrow=n,ncol=length(alpha))
for (j in 1:n){
x = matrix(nrow=1,ncol=length(alpha))
for (i in 1:length(alpha)){
x[1,i] = rgamma(n=1,shape =a+y[i])
}
z[j,] = x / sum(x)
}
return(z)
}
z = rDirichlet(n,alpha,y)
posterior_prob = mean(z[,1] > z[,3])
print(posterior_prob)
#--------------------------------3.a--------------------
library(geoR)
library(mvtnorm)
head(X)
#priors
#sigma_sq_0 = rinvchisq(n = 1,df = 1,scale = 2^2)
ncovs = dim(X)[2]
mu_0 = rep(0,ncovs)
omega_0 = 1/25*diag(ncovs)
nu_0 = 1
sigma_sq_0 = 2^2
#BayesLinReg(y,X,mu_0,omega_0,nu_0,sigma_sq_0,10000)
draws = BayesLinReg(y = y,X = X,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
intervals = matrix(nrow=ncovs,ncol=3)
colnames(intervals) = c("2.5%","mean","97.5%")
rownames(intervals) = colnames(X)
for (i in 1:ncovs){
draw_i = draws$betaSample[,i]
intervals[i,c(1,3)] = quantile(draw_i,probs=c(0.025,0.975))
intervals[i,2] = mean(draw_i)
}
intervals
#interval for b1 /x1 is positive indicating that the variable x1 is significant to our data.
#----------------------3.b---------------
posterior_median = median(draws$sigma2Sample)
posterior_median
#----------------------3.c----------------
intervals[c("x1","x1*x3","x1*x4"),]
beta1 = draws$betaSample[2,]
beta5 = draws$betaSample[6,]
beta6 = draws$betaSample[7,]
b1_B = beta1 + beta5
b1_C = beta1 + beta6
diff = b1_B - b1_C
plot(density(diff))
draws = BayesLinReg(y = y,X = X,mu_0 = mu_0,Omega_0 = omega_0,v_0 = nu_0,sigma2_0 = sigma_sq_0,nIter = 10000)
